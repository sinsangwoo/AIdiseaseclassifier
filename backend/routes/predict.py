import io
import time
from flask import Blueprint, current_app, request
from backend.utils import (
    validate_file,
    error_response,
    ModelNotLoadedError,
    FileValidationError,
    InvalidImageError,
    ImageProcessingError,
    PredictionError,
    get_logger,
    log_exception
)

predict_bp = Blueprint('predict', __name__)

@predict_bp.route("/predict", methods=['POST'])
def predict():
    """
    ì´ë¯¸ì§€ ì§ˆë³‘ ì˜ˆì¸¡ ì—”ë“œí¬ì¸íŠ¸ (Production-Grade, Phase 3-4)
    """
    start_time = time.time()
    
    model_service = current_app.model_service
    image_processor = current_app.image_processor
    image_validator = current_app.image_validator
    config = current_app.config
    
    request_logger = get_logger('aiclassifier.api')
    request_logger.info("ğŸ“¥ ì˜ˆì¸¡ ìš”ì²­ ìˆ˜ì‹ ")
    
    try:
        # 1. ëª¨ë¸ ì¤€ë¹„ ìƒíƒœ í™•ì¸
        if not model_service.is_ready():
            raise ModelNotLoadedError()
        
        # 2. íŒŒì¼ ì¡´ì¬ í™•ì¸
        if 'file' not in request.files:
            raise FileValidationError("ìš”ì²­ì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
        
        file = request.files['file']
        
        # 3. ê¸°ë³¸ íŒŒì¼ ê²€ì¦
        is_valid, error_msg = validate_file(
            file,
            allowed_extensions=config['ALLOWED_EXTENSIONS'],
            max_size=config['MAX_CONTENT_LENGTH']
        )
        
        if not is_valid:
            raise FileValidationError(error_msg)
        
        request_logger.info(f"ğŸ“„ íŒŒì¼ ìˆ˜ì‹ : {file.filename}")
        
        # 4. íŒŒì¼ ì½ê¸°
        in_memory_file = io.BytesIO()
        file.save(in_memory_file)
        in_memory_file.seek(0)
        image_bytes = in_memory_file.read()
        
        # 5. ê³ ê¸‰ ì´ë¯¸ì§€ ê²€ì¦
        if image_validator:
            image_validator.comprehensive_validation(image_bytes)
            request_logger.debug("âœ“ ê³ ê¸‰ ì´ë¯¸ì§€ ê²€ì¦ í†µê³¼")
        
        # 6. ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        processed_image = image_processor.preprocess(image_bytes)
        
        # 7. ì˜ˆì¸¡ ìˆ˜í–‰ (ìºì‹± ì§€ì›)
        predictions, from_cache = model_service.predict(processed_image)
        
        # 8. ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        processing_time_ms = (time.time() - start_time) * 1000
        
        top_result = predictions[0]
        cache_label = "ìºì‹œ íˆíŠ¸" if from_cache else "ì¶”ë¡ "
        request_logger.info(
            f"âœ… ì˜ˆì¸¡ ì™„ë£Œ [{cache_label}] - {file.filename}: "
            f"{top_result['className']} ({top_result['probability']:.4f}) "
            f"[{processing_time_ms:.0f}ms]"
        )
        
        # 9. ì‘ë‹µ ë°˜í™˜ (ë©”íƒ€ë°ì´í„° í¬í•¨)
        response = {
            'success': True,
            'predictions': predictions,
            'metadata': {
                'processing_time_ms': round(processing_time_ms, 2),
                'image_size': list(config['TARGET_IMAGE_SIZE']),
                'filename': file.filename,
                'model_version': '1.0.0-phase3-4',
                'cache_enabled': model_service.enable_cache,
                'from_cache': from_cache
            }
        }
        
        return response, 200
    
    except ModelNotLoadedError as e:
        log_exception(request_logger, e, "ëª¨ë¸ ë¯¸ì¤€ë¹„")
        return error_response(e.message, status_code=503, error_type=e.error_code)
    
    except FileValidationError as e:
        request_logger.warning(f"íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨: {e.message}")
        return error_response(e.message, status_code=400, error_type=e.error_code)
    
    except InvalidImageError as e:
        request_logger.warning(f"ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë¯¸ì§€: {e.message}")
        return error_response(e.message, status_code=400, error_type=e.error_code)
    
    except ImageProcessingError as e:
        log_exception(request_logger, e, "ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜")
        return error_response(
            e.message,
            status_code=422,
            error_type=e.error_code,
            details={"original_error": str(e.original_error)} if hasattr(e, 'original_error') and e.original_error else None
        )
    
    except PredictionError as e:
        log_exception(request_logger, e, "ì˜ˆì¸¡ ì˜¤ë¥˜")
        return error_response(
            "ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤",
            status_code=500,
            error_type=e.error_code,
            details={"original_error": str(e.original_error)} if hasattr(e, 'original_error') and e.original_error else None
        )
    
    except Exception as e:
        log_exception(request_logger, e, "ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜")
        return error_response("ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤", status_code=500, error_type="InternalServerError")
